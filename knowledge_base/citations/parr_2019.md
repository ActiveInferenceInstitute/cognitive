---
title: "Active Inference: The Free Energy Principle in Mind, Brain, and Behavior"
authors:
  - "Thomas Parr"
  - "Giovanni Pezzulo"
  - "Karl J. Friston"
type: citation
status: verified
created: 2025-01-01
year: 2019
journal: "Neuroscience & Biobehavioral Reviews"
volume: 100
pages: 1-7
doi: "10.1016/j.neubiorev.2019.02.031"
tags:
  - active_inference
  - tutorial
  - free_energy
  - review
  - neuroscience
semantic_relations:
  - type: tutorial_for
    links:
      - [[../cognitive/active_inference]]
      - [[../mathematics/free_energy_principle]]
  - type: extends
    links:
      - [[friston_2017]]
  - type: cited_by
    links:
      - [[pezzulo_2021]]
---

# Active Inference: The Free Energy Principle in Mind, Brain, and Behavior

## Authors
- **Thomas Parr** (Wellcome Trust Centre for Neuroimaging, University College London)
- **Giovanni Pezzulo** (Institute of Cognitive Sciences and Technologies, National Research Council)
- **Karl J. Friston** (Wellcome Trust Centre for Neuroimaging, University College London)

## Publication Details
- **Journal**: Neuroscience & Biobehavioral Reviews
- **Year**: 2019
- **Volume**: 100
- **Pages**: 1-7
- **DOI**: [10.1016/j.neubiorev.2019.02.031](https://doi.org/10.1016/j.neubiorev.2019.02.031)

## Abstract
This tutorial review introduces Active Inference as a unified theory of perception, action, and learning. The authors explain how the free energy principle provides a mathematical framework for understanding how biological agents perceive and act in uncertain environments, with applications to neuroscience, psychology, and artificial intelligence.

## Key Contributions

### Tutorial Framework
- **Accessible Introduction**: Clear explanation of complex concepts
- **Unified Theory**: Integration of perception, action, and learning
- **Mathematical Rigor**: Precise formulations without excessive complexity
- **Biological Plausibility**: Neurobiologically grounded mechanisms

### Core Concepts
- **Free Energy Minimization**: Universal principle for adaptive systems
- **Active Inference**: Action as inference on preferred outcomes
- **Generative Models**: Internal representations of the world
- **Precision Weighting**: Attention and salience mechanisms

### Applications
- **Neuroscience**: Predictive processing in the brain
- **Psychology**: Decision-making and behavioral control
- **Artificial Intelligence**: Novel approaches to machine learning
- **Psychiatry**: Understanding mental disorders

## Theoretical Foundations

### Free Energy Principle
The free energy principle states that adaptive systems minimize variational free energy, which provides an upper bound on surprise. This principle applies to all biological systems, from single cells to complex brains.

### Active Inference
Active Inference extends the free energy principle to action. Instead of passively perceiving the world, agents actively sample their environment to confirm their predictions. This resolves the "dark room problem" in perception.

### Generative Models
Agents maintain internal models of how the world works. These models generate predictions about sensory inputs, and the mismatch between predictions and reality drives learning and behavior.

## Mathematical Overview

### Variational Free Energy
```
F = E_{q(θ)}[ln q(θ) - ln p(y,θ|m)]
```

Where:
- `F`: Variational free energy
- `q(θ)`: Approximate posterior
- `p(y,θ|m)`: True posterior under model m
- `y`: Observed data

### Expected Free Energy
```
G(π) = E_{q(s^π)}[ln q(s^π) - ln p(o,s^π|m)]
```

Where:
- `G(π)`: Expected free energy for policy π
- `q(s^π)`: Predicted states under policy
- `p(o,s^π|m)`: Likelihood under generative model

## Neurobiological Implementation

### Predictive Coding
- **Hierarchical Processing**: Multiple cortical levels
- **Error Propagation**: Prediction errors flow upward
- **Precision Control**: Neuromodulators adjust error weighting
- **Synaptic Plasticity**: Learning through error minimization

### Action Selection
- **Policy Evaluation**: Expected free energy calculation
- **Motor Commands**: Selection of action sequences
- **Sensory Attenuation**: Reduced sensory precision during action
- **Epistemic Foraging**: Exploration for information gain

## Applications and Examples

### Perception
Active Inference explains how the brain constructs coherent perceptions from noisy sensory inputs, with applications to understanding hallucinations and illusions.

### Action
The theory provides a novel account of motor control, where actions are selected to minimize expected free energy rather than maximize expected reward.

### Learning
Learning corresponds to updating generative models to better predict sensory inputs, providing a unified account of supervised and unsupervised learning.

### Social Cognition
Active Inference extends to social interactions, where agents infer others' mental states and intentions.

## Relationship to Other Theories

### Reinforcement Learning
- Active Inference subsumes reinforcement learning
- Free energy minimization as "reward"
- Exploration through epistemic affordances

### Predictive Coding
- Active Inference extends predictive coding to action
- Unifies perception and action under single principle
- Provides normative account of neural computation

### Bayesian Brain Hypothesis
- Active Inference provides implementation
- Free energy as computational objective
- Precision weighting as attention mechanism

## Critical Assessment

### Strengths
- **Unified Framework**: Single principle explains diverse phenomena
- **Mathematical Rigor**: Precise formulations enable testing
- **Biological Plausibility**: Consistent with neurobiological data
- **Broad Applicability**: From cells to societies

### Challenges
- **Computational Complexity**: Approximate inference required
- **Empirical Testing**: Difficult to test core predictions
- **Philosophical Implications**: Questions about consciousness and qualia
- **Scale**: Bridging cellular and systems levels

## Impact and Future Directions

### Research Impact
This tutorial has become a standard introduction to Active Inference, cited extensively in neuroscience, psychology, and artificial intelligence literature.

### Future Developments
- **Scalable Algorithms**: More efficient inference methods
- **Empirical Validation**: Large-scale neural recordings
- **Clinical Applications**: Novel treatments for mental disorders
- **Artificial Systems**: AI systems based on Active Inference

## Reading Guide
1. **Introduction**: Overview of the free energy principle
2. **Perception**: How agents perceive the world
3. **Action**: How agents act on the world
4. **Learning**: How agents learn about the world
5. **Applications**: Extensions to various domains

---

> **Tutorial Excellence**: This paper provides the clearest introduction to Active Inference available.

---

> **Foundational Concepts**: Essential reading for understanding the theory's core principles.

---

> **Broad Appeal**: Accessible to readers from neuroscience, psychology, and artificial intelligence.
