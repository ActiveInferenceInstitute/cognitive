---
title: Source Code Overview
type: documentation
status: stable
created: 2025-01-01
updated: 2025-01-01
tags:
  - source
  - code
  - implementation
  - architecture
  - modules
semantic_relations:
  - type: organizes
    links:
      - [[models/README]]
      - [[utils/README]]
      - [[visualization/README]]
---

# Source Code Overview

This directory contains the core source code implementations for the cognitive modeling framework, organized into modular components for agent models, utilities, and visualization tools. The source code provides the foundational implementations that power the entire cognitive modeling ecosystem.

## ðŸ“ Source Code Structure

### Core Modules

#### Models (`models/`)
- **Active Inference** (`models/active_inference/`): Active Inference agent implementations
- **Matrices** (`models/matrices/`): Matrix operations and mathematical utilities

#### Utilities (`utils/`)
- **Core Utilities** (`utils/`): General-purpose utility functions
- **Visualization Utils** (`utils/visualization/`): Network visualization tools

#### Visualization (`visualization/`)
- **Matrix Plots** (`visualization/matrix_plots.py`): Matrix visualization functions

#### Analysis (`analysis/`)
- **Analysis Tools**: Performance analysis and evaluation utilities

## ðŸ—ï¸ Architecture Overview

### Modular Design Principles

```python
# Core architectural patterns used throughout the codebase
class ModularArchitecture:
    """Base class demonstrating modular design patterns."""

    def __init__(self, config):
        self.config = config
        self.components = {}
        self.interfaces = {}

    def register_component(self, name, component, interface=None):
        """Register a component with optional interface specification."""
        self.components[name] = component
        if interface:
            self.interfaces[name] = interface

    def get_component(self, name):
        """Retrieve a registered component."""
        return self.components.get(name)

    def validate_architecture(self):
        """Validate the overall architecture integrity."""
        # Check component compatibility
        # Validate interface contracts
        # Ensure dependency resolution
        pass
```

### Component Integration Framework

```python
class ComponentIntegrationFramework:
    """Framework for integrating source code components."""

    def __init__(self, integration_config):
        self.component_registry = ComponentRegistry()
        self.dependency_resolver = DependencyResolver()
        self.interface_validator = InterfaceValidator()
        self.integration_tester = IntegrationTester()

    def integrate_components(self, component_specs):
        """Integrate multiple components into a cohesive system."""

        # Register components
        for spec in component_specs:
            self.component_registry.register_component(spec)

        # Resolve dependencies
        dependency_graph = self.dependency_resolver.resolve_dependencies(
            self.component_registry.get_all_components()
        )

        # Validate interfaces
        interface_validation = self.interface_validator.validate_interfaces(
            dependency_graph
        )

        if not interface_validation['valid']:
            raise IntegrationError(f"Interface validation failed: {interface_validation['errors']}")

        # Create integrated system
        integrated_system = self.create_integrated_system(dependency_graph)

        # Test integration
        integration_test_results = self.integration_tester.test_integration(integrated_system)

        if not integration_test_results['passed']:
            raise IntegrationError(f"Integration tests failed: {integration_test_results['failures']}")

        return integrated_system

    def create_integrated_system(self, dependency_graph):
        """Create the final integrated system from dependency graph."""
        # Instantiate components in dependency order
        # Wire component interfaces
        # Initialize system state
        # Return integrated system
        pass
```

## ðŸ“¦ Core Component Implementations

### Active Inference Models (`models/active_inference/`)

#### Core Active Inference Agent

```python
class ActiveInferenceAgent:
    """Complete Active Inference agent implementation."""

    def __init__(self, config):
        """Initialize Active Inference agent.

        Args:
            config: Configuration dictionary containing:
                - state_space_size: Number of possible states
                - action_space_size: Number of possible actions
                - learning_rate: Learning rate for belief updates
                - precision: Precision parameter for inference
                - planning_horizon: Number of steps to plan ahead
        """

        # Core components
        self.belief_system = BeliefSystem(config)
        self.policy_system = PolicySystem(config)
        self.action_system = ActionSystem(config)
        self.learning_system = LearningSystem(config)

        # Configuration
        self.config = config
        self.state_space_size = config['state_space_size']
        self.action_space_size = config['action_space_size']

        # State tracking
        self.current_beliefs = self.initialize_beliefs()
        self.belief_history = []

    def select_action(self, observation):
        """Select action based on current observation and beliefs.

        Args:
            observation: Current environmental observation

        Returns:
            Selected action index
        """

        # Update beliefs based on observation
        self.update_beliefs(observation)

        # Evaluate policies
        policy_evaluations = self.policy_system.evaluate_policies(
            self.current_beliefs, self.config['planning_horizon']
        )

        # Select optimal policy
        optimal_policy = self.select_optimal_policy(policy_evaluations)

        # Extract first action from optimal policy
        selected_action = optimal_policy[0]

        return selected_action

    def update_beliefs(self, observation):
        """Update agent beliefs based on observation.

        Args:
            observation: New observation from environment
        """

        # Bayesian belief update
        updated_beliefs = self.belief_system.update_beliefs(
            self.current_beliefs, observation
        )

        # Store belief history
        self.belief_history.append(updated_beliefs.copy())

        # Update current beliefs
        self.current_beliefs = updated_beliefs

    def learn_from_experience(self, action, reward, next_observation):
        """Learn from experience tuple.

        Args:
            action: Action taken
            reward: Reward received
            next_observation: Next observation
        """

        # Update model parameters
        self.learning_system.update_parameters(
            self.current_beliefs, action, reward, next_observation
        )

        # Update beliefs with new observation
        self.update_beliefs(next_observation)

    def get_current_beliefs(self):
        """Get current belief state."""
        return self.current_beliefs.copy()

    def get_belief_history(self):
        """Get complete belief history."""
        return self.belief_history.copy()

    def reset(self):
        """Reset agent to initial state."""
        self.current_beliefs = self.initialize_beliefs()
        self.belief_history = []

    def initialize_beliefs(self):
        """Initialize prior beliefs."""
        # Uniform prior over states
        return np.ones(self.state_space_size) / self.state_space_size

    def select_optimal_policy(self, policy_evaluations):
        """Select optimal policy from evaluations."""
        # Select policy with minimum expected free energy
        min_efe_index = np.argmin([eval['expected_free_energy'] for eval in policy_evaluations])
        return policy_evaluations[min_efe_index]['policy']
```

#### Belief System Implementation

```python
class BeliefSystem:
    """Belief representation and updating system."""

    def __init__(self, config):
        self.state_space_size = config['state_space_size']
        self.observation_model = self.create_observation_model(config)
        self.transition_model = self.create_transition_model(config)

    def update_beliefs(self, prior_beliefs, observation):
        """Update beliefs using Bayes' rule.

        Args:
            prior_beliefs: Prior belief distribution over states
            observation: Current observation

        Returns:
            Updated belief distribution
        """

        # Compute likelihood for each state
        likelihood = np.array([
            self.observation_model.likelihood(observation, state)
            for state in range(self.state_space_size)
        ])

        # Apply Bayes' rule
        posterior_unnormalized = prior_beliefs * likelihood
        posterior = posterior_unnormalized / np.sum(posterior_unnormalized)

        return posterior

    def predict_beliefs(self, current_beliefs, action):
        """Predict next beliefs given current beliefs and action.

        Args:
            current_beliefs: Current belief distribution
            action: Action to be taken

        Returns:
            Predicted belief distribution for next state
        """

        # Use transition model to predict next state distribution
        predicted_beliefs = np.zeros(self.state_space_size)

        for current_state in range(self.state_space_size):
            for next_state in range(self.state_space_size):
                transition_prob = self.transition_model.probability(
                    next_state, current_state, action
                )
                predicted_beliefs[next_state] += (
                    current_beliefs[current_state] * transition_prob
                )

        return predicted_beliefs

    def create_observation_model(self, config):
        """Create observation model."""
        # Implementation depends on specific domain
        return ObservationModel(config)

    def create_transition_model(self, config):
        """Create transition model."""
        # Implementation depends on specific domain
        return TransitionModel(config)
```

### Matrix Operations (`models/matrices/`)

#### Matrix Operations Library

```python
class MatrixOperations:
    """Comprehensive matrix operations for cognitive modeling."""

    def __init__(self):
        self.precision = 1e-10  # Numerical precision threshold

    def matrix_inverse(self, matrix):
        """Compute matrix inverse with numerical stability.

        Args:
            matrix: Input matrix (numpy array)

        Returns:
            Matrix inverse
        """

        # Check for conditioning
        condition_number = np.linalg.cond(matrix)

        if condition_number > 1e12:
            # Use regularization for ill-conditioned matrices
            identity = np.eye(matrix.shape[0])
            regularization_term = self.precision * np.trace(matrix) / matrix.shape[0]
            matrix = matrix + regularization_term * identity

        try:
            inverse = np.linalg.inv(matrix)
            return inverse
        except np.linalg.LinAlgError:
            raise ValueError("Matrix is singular and cannot be inverted")

    def matrix_pseudoinverse(self, matrix):
        """Compute Moore-Penrose pseudoinverse.

        Args:
            matrix: Input matrix

        Returns:
            Pseudoinverse of matrix
        """

        # Use SVD for robust pseudoinverse computation
        U, s, Vt = np.linalg.svd(matrix, full_matrices=False)

        # Truncate small singular values
        s_threshold = self.precision * np.max(s)
        s_inv = np.where(s > s_threshold, 1.0 / s, 0.0)

        # Compute pseudoinverse
        pseudoinverse = Vt.T @ np.diag(s_inv) @ U.T

        return pseudoinverse

    def matrix_decomposition(self, matrix, method='svd'):
        """Perform matrix decomposition.

        Args:
            matrix: Input matrix
            method: Decomposition method ('svd', 'eigen', 'qr')

        Returns:
            Decomposition results
        """

        if method == 'svd':
            U, s, Vt = np.linalg.svd(matrix, full_matrices=False)
            return {'U': U, 's': s, 'Vt': Vt}

        elif method == 'eigen':
            eigenvalues, eigenvectors = np.linalg.eig(matrix)
            return {'eigenvalues': eigenvalues, 'eigenvectors': eigenvectors}

        elif method == 'qr':
            Q, R = np.linalg.qr(matrix)
            return {'Q': Q, 'R': R}

        else:
            raise ValueError(f"Unknown decomposition method: {method}")

    def matrix_multiplication(self, A, B, optimize=True):
        """Optimized matrix multiplication.

        Args:
            A: First matrix
            B: Second matrix
            optimize: Whether to use optimized multiplication

        Returns:
            Matrix product A @ B
        """

        if optimize:
            # Use optimized BLAS operations when available
            if hasattr(np, 'matmul'):
                return np.matmul(A, B)
            else:
                return np.dot(A, B)
        else:
            # Standard numpy multiplication
            return A @ B

    def matrix_norm(self, matrix, norm_type='frobenius'):
        """Compute matrix norm.

        Args:
            matrix: Input matrix
            norm_type: Type of norm ('frobenius', 'spectral', 'nuclear')

        Returns:
            Matrix norm value
        """

        if norm_type == 'frobenius':
            return np.linalg.norm(matrix, 'fro')
        elif norm_type == 'spectral':
            return np.linalg.norm(matrix, 2)
        elif norm_type == 'nuclear':
            return np.linalg.norm(matrix, 'nuc')
        else:
            raise ValueError(f"Unknown norm type: {norm_type}")
```

### Utility Functions (`utils/`)

#### Data Processing Utilities

```python
class DataProcessor:
    """Utilities for processing experimental and simulation data."""

    def __init__(self, processing_config=None):
        self.config = processing_config or {}
        self.preprocessing_pipeline = self.create_preprocessing_pipeline()
        self.validation_checks = self.create_validation_checks()

    def preprocess_data(self, raw_data):
        """Preprocess raw data for analysis.

        Args:
            raw_data: Raw data dictionary or array

        Returns:
            Preprocessed data
        """

        processed_data = raw_data.copy()

        # Apply preprocessing pipeline
        for step_name, step_function in self.preprocessing_pipeline.items():
            processed_data = step_function(processed_data)

        # Validate processed data
        validation_result = self.validate_data(processed_data)

        if not validation_result['valid']:
            raise DataProcessingError(f"Data validation failed: {validation_result['errors']}")

        return processed_data

    def create_preprocessing_pipeline(self):
        """Create data preprocessing pipeline."""

        pipeline = {
            'clean_missing_values': self.clean_missing_values,
            'normalize_features': self.normalize_features,
            'remove_outliers': self.remove_outliers,
            'encode_categorical': self.encode_categorical_variables
        }

        return pipeline

    def validate_data(self, data):
        """Validate processed data quality."""

        validation_result = {
            'valid': True,
            'errors': []
        }

        # Check for required fields
        required_fields = self.config.get('required_fields', [])
        for field in required_fields:
            if field not in data:
                validation_result['errors'].append(f"Missing required field: {field}")
                validation_result['valid'] = False

        # Check data types
        type_requirements = self.config.get('type_requirements', {})
        for field, expected_type in type_requirements.items():
            if field in data and not isinstance(data[field], expected_type):
                validation_result['errors'].append(
                    f"Field {field} has wrong type. Expected {expected_type}, got {type(data[field])}"
                )
                validation_result['valid'] = False

        # Check data ranges
        range_requirements = self.config.get('range_requirements', {})
        for field, (min_val, max_val) in range_requirements.items():
            if field in data:
                field_data = np.array(data[field])
                if np.any(field_data < min_val) or np.any(field_data > max_val):
                    validation_result['errors'].append(
                        f"Field {field} contains values outside range [{min_val}, {max_val}]"
                    )
                    validation_result['valid'] = False

        return validation_result

    def clean_missing_values(self, data):
        """Clean missing values in data."""
        # Implementation for handling missing values
        pass

    def normalize_features(self, data):
        """Normalize feature values."""
        # Implementation for feature normalization
        pass

    def remove_outliers(self, data):
        """Remove outlier data points."""
        # Implementation for outlier removal
        pass

    def encode_categorical_variables(self, data):
        """Encode categorical variables."""
        # Implementation for categorical encoding
        pass
```

### Visualization Tools (`visualization/`)

#### Matrix Visualization

```python
class MatrixVisualizer:
    """Visualization tools for matrices and tensors."""

    def __init__(self, visualization_config=None):
        self.config = visualization_config or {}
        self.colormap = self.config.get('colormap', 'viridis')
        self.figure_size = self.config.get('figure_size', (10, 8))

    def plot_matrix(self, matrix, title="Matrix Visualization",
                   save_path=None, show_plot=True):
        """Plot matrix as heatmap.

        Args:
            matrix: 2D numpy array to visualize
            title: Plot title
            save_path: Path to save plot (optional)
            show_plot: Whether to display plot
        """

        plt.figure(figsize=self.figure_size)

        # Create heatmap
        im = plt.imshow(matrix, cmap=self.colormap, aspect='auto')

        # Add colorbar
        plt.colorbar(im)

        # Add title and labels
        plt.title(title)
        plt.xlabel('Columns')
        plt.ylabel('Rows')

        # Save plot if requested
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        # Show plot if requested
        if show_plot:
            plt.show()
        else:
            plt.close()

    def plot_matrix_evolution(self, matrix_sequence, title="Matrix Evolution",
                             save_path=None, animation_duration=500):
        """Create animation of matrix evolution over time.

        Args:
            matrix_sequence: Sequence of matrices
            title: Animation title
            save_path: Path to save animation
            animation_duration: Duration per frame in milliseconds
        """

        fig, ax = plt.subplots(figsize=self.figure_size)

        def animate(frame):
            ax.clear()
            matrix = matrix_sequence[frame]
            im = ax.imshow(matrix, cmap=self.colormap, aspect='auto')
            ax.set_title(f'{title} - Frame {frame}')
            return [im]

        # Create animation
        anim = animation.FuncAnimation(
            fig, animate, frames=len(matrix_sequence),
            interval=animation_duration, blit=True
        )

        # Save animation if requested
        if save_path:
            anim.save(save_path, writer='ffmpeg', fps=1000/animation_duration)

        plt.close()
        return anim

    def plot_matrix_comparison(self, matrices, titles, save_path=None):
        """Plot multiple matrices for comparison.

        Args:
            matrices: List of matrices to compare
            titles: List of titles for each matrix
            save_path: Path to save comparison plot
        """

        n_matrices = len(matrices)
        n_cols = min(3, n_matrices)
        n_rows = (n_matrices + n_cols - 1) // n_cols

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 3))

        if n_rows == 1:
            axes = axes.reshape(1, -1)
        if n_cols == 1:
            axes = axes.reshape(-1, 1)

        for i, (matrix, title) in enumerate(zip(matrices, titles)):
            row, col = i // n_cols, i % n_cols
            ax = axes[row, col]

            im = ax.imshow(matrix, cmap=self.colormap, aspect='auto')
            ax.set_title(title)

            # Add colorbar for each subplot
            plt.colorbar(im, ax=ax, shrink=0.8)

        # Hide empty subplots
        for i in range(len(matrices), n_rows * n_cols):
            row, col = i // n_cols, i % n_cols
            axes[row, col].set_visible(False)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()
```

## ðŸ”§ Development and Testing

### Code Organization Standards

```python
# Standard file structure for source modules
"""
src/
â”œâ”€â”€ __init__.py                 # Package initialization
â”œâ”€â”€ models/                     # Model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ active_inference/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py           # Main agent class
â”‚   â”‚   â”œâ”€â”€ belief_system.py   # Belief management
â”‚   â”‚   â”œâ”€â”€ policy_system.py   # Policy evaluation
â”‚   â”‚   â””â”€â”€ tests/             # Unit tests
â”‚   â””â”€â”€ matrices/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ operations.py      # Core operations
â”‚       â””â”€â”€ tests/
â”œâ”€â”€ utils/                      # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ network_viz.py
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ visualization/              # Visualization tools
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ matrix_plots.py
â”‚   â””â”€â”€ tests/
â””â”€â”€ tests/                      # Integration tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_models.py
    â””â”€â”€ test_utils.py
"""
```

### Testing Framework

```python
# Standard testing patterns
import pytest
import numpy as np
from src.models.active_inference import ActiveInferenceAgent

class TestActiveInferenceAgent:
    """Test suite for Active Inference agent."""

    @pytest.fixture
    def agent_config(self):
        """Standard agent configuration for testing."""
        return {
            'state_space_size': 5,
            'action_space_size': 3,
            'learning_rate': 0.01,
            'precision': 1.0,
            'planning_horizon': 2
        }

    @pytest.fixture
    def agent(self, agent_config):
        """Create agent instance for testing."""
        return ActiveInferenceAgent(agent_config)

    def test_agent_initialization(self, agent, agent_config):
        """Test agent initializes correctly."""
        assert agent.state_space_size == agent_config['state_space_size']
        assert agent.action_space_size == agent_config['action_space_size']
        assert len(agent.get_current_beliefs()) == agent_config['state_space_size']

    def test_belief_update(self, agent):
        """Test belief updating mechanism."""
        initial_beliefs = agent.get_current_beliefs()

        # Simulate observation
        observation = 0  # Example observation
        agent.update_beliefs(observation)

        updated_beliefs = agent.get_current_beliefs()

        # Beliefs should be updated
        assert not np.array_equal(initial_beliefs, updated_beliefs)

        # Beliefs should sum to 1 (be a valid probability distribution)
        assert np.isclose(np.sum(updated_beliefs), 1.0)

    def test_action_selection(self, agent):
        """Test action selection functionality."""
        observation = 0

        action = agent.select_action(observation)

        # Action should be valid
        assert isinstance(action, (int, np.integer))
        assert 0 <= action < agent.action_space_size

    def test_learning(self, agent):
        """Test learning from experience."""
        initial_beliefs = agent.get_current_beliefs()

        # Simulate learning episode
        for _ in range(10):
            observation = np.random.randint(0, agent.state_space_size)
            action = agent.select_action(observation)
            reward = np.random.random()
            next_observation = np.random.randint(0, agent.state_space_size)

            agent.learn_from_experience(action, reward, next_observation)

        # Beliefs should have changed through learning
        final_beliefs = agent.get_current_beliefs()
        assert not np.array_equal(initial_beliefs, final_beliefs)
```

## ðŸ“Š Performance and Optimization

### Performance Monitoring

```python
class PerformanceMonitor:
    """Monitor source code performance."""

    def __init__(self):
        self.metrics = {}
        self.baselines = {}

    def monitor_function(self, func):
        """Decorator to monitor function performance."""

        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss

            try:
                result = func(*args, **kwargs)
                success = True
                error = None
            except Exception as e:
                result = None
                success = False
                error = str(e)

            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss

            execution_time = end_time - start_time
            memory_usage = end_memory - start_memory

            # Store metrics
            func_name = func.__name__
            if func_name not in self.metrics:
                self.metrics[func_name] = []

            self.metrics[func_name].append({
                'timestamp': datetime.now(),
                'execution_time': execution_time,
                'memory_usage': memory_usage,
                'success': success,
                'error': error
            })

            return result

        return wrapper

    def get_performance_report(self, func_name):
        """Generate performance report for function."""

        if func_name not in self.metrics:
            return None

        metrics = self.metrics[func_name]

        execution_times = [m['execution_time'] for m in metrics]
        memory_usages = [m['memory_usage'] for m in metrics]
        success_rate = sum(1 for m in metrics if m['success']) / len(metrics)

        report = {
            'function_name': func_name,
            'call_count': len(metrics),
            'success_rate': success_rate,
            'avg_execution_time': np.mean(execution_times),
            'std_execution_time': np.std(execution_times),
            'avg_memory_usage': np.mean(memory_usages),
            'max_memory_usage': np.max(memory_usages),
            'performance_trend': self.analyze_performance_trend(metrics)
        }

        return report
```

## ðŸ“š Related Documentation

### Implementation References
- [[models/README|Models Overview]]
- [[utils/README|Utilities Overview]]
- [[../README|Tools Overview]]

### Development Resources
- [[../../docs/api/README|API Documentation]]
- [[../../docs/implementation/README|Implementation Guides]]
- [[../../tests/README|Testing Framework]]

### Quality Assurance
- [[../../docs/repo_docs/code_standards|Code Standards]]
- [[../../docs/repo_docs/unit_testing|Testing Guidelines]]

## ðŸ”— Cross-References

### Core Components
- [[models/active_inference/|Active Inference Implementation]]
- [[models/matrices/|Matrix Operations]]
- [[utils/visualization/|Visualization Utilities]]

### Integration Points
- [[../../Things/|Implementation Examples]]
- [[../../docs/examples/|Usage Examples]]
- [[../../docs/guides/|Development Guides]]

---

> **Architecture**: The source code follows modular design principles with clear separation of concerns and well-defined interfaces.

---

> **Testing**: All source code components include comprehensive unit tests and integration tests to ensure reliability.

---

> **Performance**: Code is optimized for performance while maintaining readability and maintainability.
